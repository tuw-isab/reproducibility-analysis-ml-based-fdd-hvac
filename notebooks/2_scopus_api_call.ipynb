{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering Bibliometric Information\n",
    "In order make an analyisis and correlation between the reproducability, the paper citations and the scientific background of the authors possible bibliometric information is needed. This information is mostly gathered via the `Scopus API`. \n",
    "\n",
    "The follwing data was collected via the API based on the DOI of the papers:\n",
    "- citation-count\n",
    "- authors\n",
    "    - author-url\n",
    "    - given-name\n",
    "    - surname\n",
    "    - document-count\n",
    "    - cited-by-count\n",
    "    - citation-count\n",
    "    - h-index\n",
    "    - current-affiliation\n",
    "    - first-affiliation\n",
    "    - subject-area\n",
    "\n",
    "This was done with the code provided below. However, three DOIs could not be found via the API. This information was retrieved manually (details below at the specific cell). \n",
    "\n",
    "Furthermore the type of affiliation of each of the authors was classified by two researchers manually (see `affil-type` variable). The classes where \"University\", \"Industry\" and \"non-academic research\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Papameters\n",
    "save_data = False # Saves data to system\n",
    "use_local_data = True # Uses local data inestead of the API fetch\n",
    "local_data_path = '../data/local/' # Path to local data \n",
    "os.makedirs(local_data_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scopus API Calling function and parsers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_publication_data(doi, headers, collect_author_data=True):\n",
    "    api_call = f'http://api.elsevier.com/content/search/scopus?query=DOI({doi})&field=citedby-count,author-url'\n",
    "    response = requests.get(api_call, headers=headers).json().get(\"search-results\", {}).get('entry', [{}]) \n",
    "\n",
    "    response = [entry for entry in response if 'author' in entry][0]\n",
    "    publication_data = None\n",
    "    try:\n",
    "        authors = response.get(\"author\", [{}])\n",
    "        author_urls = [author.get(\"author-url\", {}) for author in authors]\n",
    "        citation_count = response.get(\"citedby-count\", 'Unknown')\n",
    "        if collect_author_data:\n",
    "            authors_data = [get_author_data(author_url, headers) for author_url in author_urls]\n",
    "        publication_data = {\n",
    "            \"doi\": doi,\n",
    "            \"citation-count\": citation_count,\n",
    "            \"authors\": authors_data if collect_author_data else author_urls, \n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f'Doi: {doi}')\n",
    "        print(e)\n",
    "    return publication_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author_data(author_url, headers):\n",
    "    response = (requests\n",
    "                .get(f'{author_url}?view=ENHANCED&field=affiliation-current,affiliation-history,given-name,surname,cited-by-count,citation-count,document-count,subject-areas,h-index', headers=headers)\n",
    "                .json()\n",
    "                .get(\"author-retrieval-response\", [{}])\n",
    "                [0]\n",
    "                )\n",
    "    author_id = author_url.split('/')[-1]\n",
    "    response_author = (requests\n",
    "                .get(f'https://api.elsevier.com/content/search/author?query=au-id({author_id})', headers=headers)\n",
    "                .json()\n",
    "                )\n",
    "\n",
    "    author_id = author_url.split('/')[-1]\n",
    "    # first_affiliation, affiliations = get_author_first_affiliation(author_id, headers)\n",
    "    affiliation_keys = ['affiliation-name', 'affiliation-city', 'affiliation-country']\n",
    "    \n",
    "    author_data = None\n",
    "    try:\n",
    "        affiliation = response.get('affiliation-current', {})\n",
    "        author_data = {\n",
    "            \"author-url\": author_url,\n",
    "            \"given-name\": response.get('preferred-name', {}).get('given-name', 'Unknown'),\n",
    "            \"surname\": response.get('preferred-name', {}).get('surname', 'Unknown'),\n",
    "            \"document-count\": response.get('coredata', {}).get('document-count', 'Unknown'),\n",
    "            \"cited-by-count\": response.get('coredata', {}).get('cited-by-count', 'Unknown'),\n",
    "            \"citation-count\": response.get('coredata', {}).get('citation-count', 'Unknown'),\n",
    "            \"h-index\": response.get('h-index', 'Unknown'),\n",
    "            \"current-affiliation\": ', '.join([str(affiliation.get(key, 'Unknown')) for key in affiliation_keys]),\n",
    "            # \"first-affiliation\": first_affiliation,\n",
    "            \"subject-area\": parse_subjects(response_author),\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f'Author url: {author_url}')\n",
    "        print('Response:', response)\n",
    "        print('Response all:', response_author)\n",
    "        print(e)\n",
    "    return author_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author_first_affiliation(author_id, headers):\n",
    "    response = requests.get(f'https://api.elsevier.com/content/search/scopus?query=AU-ID({author_id})&sort=pubyear', headers=headers).json()\n",
    "    first_affil = None\n",
    "    affils = []\n",
    "    try:\n",
    "        affiliation_keys = ['affilname', 'affiliation-city', 'affiliation-country']\n",
    "\n",
    "        affiliation = response.get('search-results', {}).get('entry', [{}])[0].get('affiliation', [{}])[0]\n",
    "        first_affil = ', '.join([str(affiliation.get(key, 'Unknown')) for key in affiliation_keys])\n",
    "\n",
    "        affiliations = response.get('search-results', {}).get('entry', [{}])[0].get('affiliation', [{}])\n",
    "        for affiliation in affiliations:\n",
    "            affils.append(', '.join([str(affiliation.get(key, 'Unknown')) for key in affiliation_keys]))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'Author id: {author_id}')\n",
    "        print(e)\n",
    "    return first_affil, affils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_subjects(response):\n",
    "    subjects = response.get(\"search-results\", [{}]).get(\"entry\", [{}])[0].get(\"subject-area\", 'Unknown')\n",
    "    subjects_dict = {}\n",
    "    if type(subjects) is list:\n",
    "        for subject in subjects:\n",
    "            subjects_dict[subject.get('$')] = subject.get('@frequency', 'Unknown')\n",
    "    elif type(subjects) is dict:\n",
    "        subjects_dict[subjects.get('$')] = subjects.get('@frequency', 'Unknown')\n",
    "    else:\n",
    "        subjects_dict['Unknown'] = 'Unknown'\n",
    "        print('Unknown subjects format:', subjects, type(subjects))\n",
    "    return subjects_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering Information\n",
    "\n",
    "In order to have access to the Scopus API an APIKey must be availalbe. Caution you need to have access to scopus (maybe universtity VPN requiered)\n",
    "\n",
    "Therefore an `.env` file that contains a line like: API_KEY=your_api_key_here should be created. Afterwards load the API key from the `.env` file for security and flexibility.\n",
    "This keeps the API key out of the source code and version control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API key from dotenv file\n",
    "load_dotenv() \n",
    "\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "\n",
    "headers = {\n",
    "    \"X-ELS-APIKey\": f'{api_key}',\n",
    "    \"Accept\": \"application/json\"\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve publication and author data\n",
    "Retrieve informations of all DOIs listed in the `papers_reviewed_cleaned.csv`file.\n",
    "\n",
    "In addition store all DOIs that could not be found in an list for later manual retrievel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DOIs\n",
    "DOIs = pd.read_csv('../data/papers_reviewed_reprod_variables_categoric.csv', usecols=['DOI_short'])\n",
    "publication_data = []\n",
    "notFoundDOIs = []\n",
    "\n",
    "if not use_local_data:\n",
    "\n",
    "    for doi in tqdm(DOIs.values, desc='Fetching Scopus API data'):\n",
    "        try:\n",
    "            publication_data.append(get_publication_data(doi[0], headers, collect_author_data=True))\n",
    "        except Exception as e:\n",
    "            print(f'Error fetching data for DOI: {doi[0]}')\n",
    "            print(e)\n",
    "            notFoundDOIs.append(doi[0])\n",
    "        \n",
    "    print(f'Number of DOIs not found: {len(notFoundDOIs)}')\n",
    "    print(f'Not found DOIs: {notFoundDOIs}')\n",
    "\n",
    "    if save_data:\n",
    "        try:\n",
    "            with open(f'{local_data_path}publication_data.json', 'w') as json_file:\n",
    "                json.dump(publication_data, json_file, indent=4)\n",
    "        except Exception as e:\n",
    "            print(f'Error saving data: {e}')\n",
    "\n",
    "else:\n",
    "    with open(f'{local_data_path}publication_data.json', 'r') as json_file:\n",
    "        publication_data = json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve not (automatically) found DOIs manually\n",
    "\n",
    "Three papers could not be found via the Scopus API search. Therefore the information of these publications needed to be retrieved manually and added to the `missing_information` variable below. \n",
    "\n",
    "The latter two publication (`https://dl.acm.org/doi/10.5555/2873021.2873029` and `10.26868/25222708.2019.210311`) could be found via manual search on the Scopus webpage. Where the citations and author-urls where collected from. The third publication could only be found on `https://dl.acm.org/`. Regarding the citaitons of the publication different values where found, `adl.acm.org` listed 0 citations whereas Google Scholar listed 1 citation (see `https://scholar.google.com/scholar?cites=11212822057543812296&as_sdt=2005&sciodt=0,5&hl=de`). Subsiquently the Google Scholar value of 1 was used. The authors were manually search in the scopus database (webfrontend) and added with there author-url. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_information = [\n",
    "    {\n",
    "        \"doi\": \"https://dl.acm.org/doi/10.5555/3615924.3623632\",\n",
    "        \"citation-count\": \"1\",\n",
    "        \"authors\": [\n",
    "            {\"author-url\": \"https://api.elsevier.com/content/author/author_id/58172106500\"},\n",
    "            {\"author-url\": \"https://api.elsevier.com/content/author/author_id/57205485739\"},\n",
    "            {\"author-url\": \"https://api.elsevier.com/content/author/author_id/6602631556\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"doi\": \"https://dl.acm.org/doi/10.5555/2873021.2873029\",\n",
    "        \"scopus-publication-id\": \"84937434978\",\n",
    "        \"citation-count\": \"9\",\n",
    "        \"authors\": [\n",
    "            {\"author-url\": \"https://api.elsevier.com/content/author/author_id/56727125200\"},\n",
    "            {\"author-url\": \"https://api.elsevier.com/content/author/author_id/56727971700\"},\n",
    "            {\"author-url\": \"https://api.elsevier.com/content/author/author_id/57212926253\"},\n",
    "            {\"author-url\": \"https://api.elsevier.com/content/author/author_id/36701070400\"},\n",
    "            {\"author-url\": \"https://api.elsevier.com/content/author/author_id/36701070400\"},\n",
    "            {\"author-url\": \"https://api.elsevier.com/content/author/author_id/56728508600\"},\n",
    "            {\"author-url\": \"https://api.elsevier.com/content/author/author_id/57217189030\"},\n",
    "            {\"author-url\": \"https://api.elsevier.com/content/author/author_id/56728761200\"},\n",
    "            {\"author-url\": \"https://api.elsevier.com/content/author/author_id/54079611600\"},\n",
    "            {\"author-url\": \"https://api.elsevier.com/content/author/author_id/36702009900\"},\n",
    "            {\"author-url\": \"https://api.elsevier.com/content/author/author_id/7404910952\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"doi\": \"10.26868/25222708.2019.210311\",\n",
    "        \"scopus-publication-id\": \"85103634671\",\n",
    "        \"citation-count\": \"7\",\n",
    "        \"authors\": [\n",
    "            {\"author-url\": \"https://api.elsevier.com/content/author/author_id/57207960636\"},\n",
    "            {\"author-url\": \"https://api.elsevier.com/content/author/author_id/15831158200\"},\n",
    "            {\"author-url\": \"https://api.elsevier.com/content/author/author_id/55673143000\"},\n",
    "            {\"author-url\": \"https://api.elsevier.com/content/author/author_id/57207965928\"},\n",
    "            {\"author-url\": \"https://api.elsevier.com/content/author/author_id/57207965458\"}\n",
    "        ]\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_local_data:\n",
    "    for paper in tqdm(missing_information):\n",
    "        for author in paper['authors']:\n",
    "            if 'author-url' in author:\n",
    "                author_url = author['author-url']\n",
    "                author_data = get_author_data(author_url, headers)\n",
    "                if author_data is None:\n",
    "                    continue\n",
    "                author.update(author_data)\n",
    "\n",
    "    if save_data:\n",
    "        with open(f'{local_data_path}missing_information.json', 'w') as json_file:\n",
    "            json.dump(missing_information, json_file, indent=4)\n",
    "else:\n",
    "    with open(f'{local_data_path}missing_information.json', 'r') as json_file:\n",
    "        missing_information = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining both publication data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "publication_data_combined = publication_data + missing_information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding the affiliation type manually\n",
    "\n",
    "In addition the the informations retrieved above the type of alliation should be investigated. Therefore two researchers have manually classified all authors into either `University`, `Industry` or `non-academic research`. The labelling data can be found in the data folder as `affil_types.csv`.\n",
    "\n",
    "The combined file the publication data with the affilation types is stored as `bibliometric_data.json`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/affil_types.json', 'r') as json_file:\n",
    "    affil_types = json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for paper in publication_data_combined:\n",
    "    for author in paper['authors']:\n",
    "        affil_type = affil_types[author['author-url']]\n",
    "        author['affil-type'] = affil_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commented out to avoid overwriting the file\n",
    "if save_data:\n",
    "    with open('../data/bibliometric_data.json', 'w') as json_file:\n",
    "        json.dump(publication_data_combined, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
